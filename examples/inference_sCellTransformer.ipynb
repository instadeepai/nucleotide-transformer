{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "edrfY09jfn32"
      },
      "source": [
        "# Inference with sCellTransformer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "[![Open All Collab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/instadeepai/nucleotide-transformer/blob/main/examples/inference_sCellTransformer.ipynb)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SWffCMcBfn37"
      },
      "source": [
        "## Installation and imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip install scikit-learn\n",
        "!pip install torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "alzkIxk9fn38"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "try:\n",
        "    import nucleotide_transformer\n",
        "except:\n",
        "    !pip install git+https://github.com/instadeepai/nucleotide-transformer@main |tail -n 1\n",
        "    import nucleotide_transformer\n",
        "\n",
        "if \"COLAB_TPU_ADDR\" in os.environ:\n",
        "    from jax.tools import colab_tpu\n",
        "\n",
        "    colab_tpu.setup_tpu()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zkTU4k4_fn39",
        "outputId": "a04ca440-be95-49e1-b683-bf5b70d00777"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/miniconda3/envs/debug_segment_enformer/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Devices found: [CpuDevice(id=0)]\n"
          ]
        }
      ],
      "source": [
        "import haiku as hk\n",
        "import jax\n",
        "import jax.numpy as jnp\n",
        "import numpy as np\n",
        "from sklearn.metrics import matthews_corrcoef\n",
        "from nucleotide_transformer.sCellTransformer.model import build_long_range_nt_fn\n",
        "from nucleotide_transformer.sCellTransformer.params import download_ckpt\n",
        "from nucleotide_transformer.sCellTransformer.get_paper_dataset import get_dataset_dataloader\n",
        "\n",
        "jax.config.update(\"jax_platform_name\", \"cpu\")\n",
        "\n",
        "backend = \"cpu\"\n",
        "devices = jax.devices(backend)\n",
        "num_devices = len(devices)\n",
        "print(f\"Devices found: {devices}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading model's weights...\n"
          ]
        }
      ],
      "source": [
        "parameters, config = download_ckpt()\n",
        "forward_fn = build_long_range_nt_fn(config)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "forward_fn = hk.transform(forward_fn)\n",
        "apply_fn = jax.pmap(forward_fn.apply, devices=devices, donate_argnums=(0,))\n",
        "\n",
        "# Put required quantities for the inference on the devices. This step is not\n",
        "# reproduced in the second inference since the quantities will already be loaded\n",
        "# on the devices !\n",
        "random_key = jax.random.PRNGKey(seed=0)\n",
        "keys = jax.device_put_replicated(random_key, devices=devices)\n",
        "parameters = jax.device_put_replicated(parameters, devices=devices)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "num_cells = config.num_cells\n",
        "dummy_gene_expressions = np.random.randint(0, 5, size=(num_devices, 1, 19968 * num_cells))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yLOOWXYluU7p"
      },
      "source": [
        "## Infer on batch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8LsaW7SJtv2W",
        "outputId": "220db929-098d-4b69-9571-4f98fee2920c"
      },
      "outputs": [],
      "source": [
        "# Infer\n",
        "outs = apply_fn(parameters, keys, dummy_gene_expressions) \n",
        "\n",
        "# Obtain the logits over the genomic features\n",
        "logits = outs[\"logits\"]\n",
        "probabilities = np.asarray(jax.nn.softmax(logits[0, :, :, :5], axis=-1))[...,-1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p7F_gS2ItzDa",
        "outputId": "4bc9c3c4-5673-433f-bd0a-7190704447f6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(1, 998400)"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "probabilities.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Replicate example from the paper"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Dataloader and parameters\n",
        "dataloader = get_dataset_dataloader(config, batch_size=1)\n",
        "mask_ratio = 0.15\n",
        "num_batches = 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1/1\n",
            "Overall MCC: 0.2307\n"
          ]
        }
      ],
      "source": [
        "# Lists to store true and predicted values for masked tokens\n",
        "all_true_values = []\n",
        "all_pred_values = []\n",
        "\n",
        "# Iterate over specified number of batches\n",
        "iterator = iter(dataloader)\n",
        "\n",
        "for batch_idx in range(num_batches):\n",
        "    try:\n",
        "        # Get next batch\n",
        "        batch = next(iterator)\n",
        "\n",
        "        # Move batch to the same device as model\n",
        "        gene_expressions = jnp.array(batch[\"gene_expressions\"])\n",
        "\n",
        "        # Create random mask\n",
        "        mask = jax.random.uniform(jax.random.PRNGKey(0), shape=gene_expressions.shape) < mask_ratio\n",
        "\n",
        "        # Clone and mask gene expressions\n",
        "        masked_gene_expressions = gene_expressions.copy()\n",
        "        masked_gene_expressions = jnp.where(mask, config.mask_token_id, gene_expressions)\n",
        "\n",
        "        # Keep original values before masking for evaluation\n",
        "        true_values = np.asarray(gene_expressions[mask])\n",
        "\n",
        "        # Convert to jax and replicate over devices\n",
        "        masked_gene_expressions = jnp.array(masked_gene_expressions)\n",
        "        masked_gene_expressions = jnp.expand_dims(masked_gene_expressions, axis=0)\n",
        "        random_key = jax.random.PRNGKey(seed=0)\n",
        "        keys = jax.device_put_replicated(random_key, devices=devices)\n",
        "\n",
        "        # Forward pass without gradient computation\n",
        "        outs = apply_fn(parameters, keys, masked_gene_expressions) \n",
        "        logits = np.asarray(outs[\"logits\"][0])\n",
        "\n",
        "        # Get predictions (assuming classification - adjust if regression)\n",
        "        predictions = np.argmax(logits, axis=-1)\n",
        "        pred_values = predictions[mask]\n",
        "\n",
        "        # Store true and predicted values\n",
        "        all_true_values.append(true_values)\n",
        "        all_pred_values.append(pred_values)\n",
        "\n",
        "        print(f\"Processed batch {batch_idx + 1}/{num_batches}\")\n",
        "\n",
        "    except StopIteration:\n",
        "        print(f\"DataLoader exhausted after {batch_idx} batches\")\n",
        "        break\n",
        "\n",
        "# Concatenate all batches\n",
        "all_true_values = np.concatenate(all_true_values)\n",
        "all_pred_values = np.concatenate(all_pred_values)\n",
        "\n",
        "# Compute Matthews Correlation Coefficient\n",
        "mcc = matthews_corrcoef(all_true_values, all_pred_values)\n",
        "print(f\"Overall MCC: {mcc:.4f}\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "debug_segment_enformer",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
