{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Installation and Imports\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from flax import nnx\n",
        "import matplotlib.pyplot as plt\n",
        "from mpl_toolkits.axes_grid1 import make_axes_locatable\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "# A. Pre-Trained Model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from nucleotide_transformer_v3.pretrained import get_pretrained_ntv3_model\n",
        "\n",
        "# Load the pre-trained 106M model\n",
        "pretrained_model, tokenizer, config = get_pretrained_ntv3_model(\n",
        "    model_name=\"NTv3_100M_pre\",\n",
        "    embeddings_layers_to_save=(6,), \n",
        "    attention_maps_to_save=((6, 1),),\n",
        "    use_bfloat16=True, # use bfloat16 for lower memory usage default is False\n",
        ")\n",
        "\n",
        "print(f\"\\nModel config:\")\n",
        "print(f\"  - Embedding dim: {config.embed_dim}\")\n",
        "print(f\"  - Num layers: {config.num_layers}\")\n",
        "print(f\"  - Attention heads: {config.attention_heads}\")\n",
        "print(f\"  - Num transformer blocks: {len(pretrained_model.transformer_blocks)}\")\n",
        "print(f\"  - Num downsamples: {config.num_downsamples}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Model Architecture Visualization\n",
        "\n",
        "The NTv3 model uses a **U-Net-like architecture** with the following key components:\n",
        "\n",
        "- **Downsampling tower**: Convolutional layers that reduce sequence length by factors of 2\n",
        "- **Transformer blocks**: Self-attention layers that process compressed representations  \n",
        "- **Upsampling tower**: Deconvolutional layers that restore original sequence resolution\n",
        "- **Skip connections**: Connect downsampling and upsampling layers for information flow\n",
        "\n",
        "Below, we visualize the complete model structure using Flax's `nnx.display()` function, which shows the hierarchical organization of all model components, their shapes, and parameter counts.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualize the model architecture\n",
        "nnx.display(pretrained_model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Tokenize DNA sequences\n",
        "\n",
        "NTv3 uses single nucleotide tokenization. Sequences should be multiples of `2^num_downsamples` (128 for 7 downsamples).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Example DNA sequences (padded to 256 nucleotides for demo)\n",
        "# generate 2 random ATCG string length 2**15\n",
        "import random\n",
        "sequences = [\n",
        "    \"\".join(random.choices(\"ATCG\", k=2**15)),\n",
        "    \"\".join(random.choices(\"ATCG\", k=2**15)),\n",
        "]\n",
        "# Tokenize\n",
        "tokens = tokenizer.batch_np_tokenize(sequences)\n",
        "\n",
        "print(f\"Input shape: {tokens.shape}\")\n",
        "print(f\"Sequence length: {len(sequences[0])} nucleotides\")\n",
        "print(f\"Pad token ID: {tokenizer.pad_token_id}\")\n",
        "print(f\"Mask token ID: {tokenizer.mask_token_id}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Run inference\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%time\n",
        "# Run inference\n",
        "outs = pretrained_model(tokens)\n",
        "\n",
        "print(f\"\\nOutput keys: {outs.keys()}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Retrieve embeddings\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Get embeddings from layer 12\n",
        "embeddings = outs[\"embeddings_6\"]\n",
        "print(f\"Embeddings shape: {embeddings.shape}\")\n",
        "print(f\"  (batch_size, sequence_length, embed_dim)\")\n",
        "\n",
        "# Final embeddings after deconv tower\n",
        "final_embeddings = outs[\"embedding\"]\n",
        "print(f\"\\nFinal embeddings shape: {final_embeddings.shape}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Compute mean embeddings\n",
        "\n",
        "For sequence-level representations, we can compute mean embeddings (excluding padding).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create padding mask\n",
        "padding_mask = jnp.expand_dims(tokens != tokenizer.pad_token_id, axis=-1)\n",
        "masked_embeddings = final_embeddings * padding_mask\n",
        "\n",
        "# Compute mean embeddings\n",
        "sequences_lengths = jnp.sum(padding_mask, axis=1)\n",
        "mean_embeddings = jnp.sum(masked_embeddings, axis=1) / sequences_lengths\n",
        "\n",
        "print(f\"Mean embeddings shape: {mean_embeddings.shape}\")\n",
        "print(f\"  (batch_size, embed_dim)\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Plot attention maps"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "num_downsamples = config.num_downsamples\n",
        "base_pairs_per_token = 2 ** num_downsamples\n",
        "fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(14, 6))\n",
        "\n",
        "padding_mask = jnp.expand_dims(tokens != tokenizer.pad_token_id, axis=-1)\n",
        "sequences_lengths = jnp.sum(padding_mask, axis=1)\n",
        "seq_length0, seq_length1 = int(sequences_lengths[0][0]), int(sequences_lengths[1][0])\n",
        "\n",
        "# ticks at start, middle, end (bp)\n",
        "x_labels = np.array([0, seq_length0 // 2, max(seq_length0 - 1, 0)])\n",
        "y_labels = np.array([0, seq_length0 // 2, max(seq_length0 - 1, 0)])\n",
        "x_ticks = x_labels // base_pairs_per_token\n",
        "y_ticks = y_labels // base_pairs_per_token\n",
        "\n",
        "# plot for first seq in the batch\n",
        "im0 = axes[0].imshow(\n",
        "    outs[\"attention_map_layer_6_number_1\"][\n",
        "        0, 1 : (seq_length0 + 1), 1 : (seq_length0 + 1)\n",
        "    ]\n",
        ")\n",
        "divider0 = make_axes_locatable(axes[0])\n",
        "cax0 = divider0.append_axes(\"right\", size=\"5%\", pad=0.05)\n",
        "fig.colorbar(im0, cax=cax0, orientation=\"vertical\")\n",
        "\n",
        "axes[0].set_xticks(x_ticks)\n",
        "axes[0].set_yticks(y_ticks)\n",
        "axes[0].set_xticklabels(x_labels, rotation=45)\n",
        "axes[0].set_yticklabels(y_labels)\n",
        "axes[0].set_xlabel(\"Position (bp)\")\n",
        "axes[0].set_ylabel(\"Position (bp)\")\n",
        "\n",
        "# plot for second seq in the batch\n",
        "im1 = axes[1].imshow(\n",
        "    outs[\"attention_map_layer_6_number_1\"][\n",
        "        1, 1 : (seq_length1 + 1), 1 : (seq_length1 + 1)\n",
        "    ]\n",
        ")\n",
        "divider1 = make_axes_locatable(axes[1])\n",
        "cax1 = divider1.append_axes(\"right\", size=\"5%\", pad=0.05)\n",
        "fig.colorbar(im1, cax=cax1, orientation=\"vertical\")\n",
        "axes[1].set_xticks(x_ticks)\n",
        "axes[1].set_yticks(y_ticks)\n",
        "axes[1].set_xticklabels(x_labels, rotation=45)\n",
        "axes[1].set_yticklabels(y_labels)\n",
        "axes[1].set_xlabel(\"Position (bp)\")\n",
        "axes[1].set_ylabel(\"Position (bp)\")\n",
        "\n",
        "fig.tight_layout()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
